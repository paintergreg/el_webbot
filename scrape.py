#!/usr/bin/env python3
#

from bs4 import BeautifulSoup
import requests
import os
import signal
from utilities import folderInitialize, keyBoardInput, signal_handler


#####################################################################
#
# Start at the http://www.emblibrary.com/EL/New.aspx
# or the user entered url.  Search for all product links.
# Then follow those links.  Search for the links within the span
# of class=sizeSpan
#
def findLinks(url):
    r = requests.get(url)
    soup = BeautifulSoup(r.content, 'html.parser')
    #
    # Find all the anchor tags that reference design details.
    # There may be different sizes for each design.  Follow each
    # size reference.
    #
    for link in soup.select('span.sizeSpan a'):
        href = link.get('href')
        params = href.split('=')  # params[2] is the productID
        designDetail(params[2], href)  # This function follows design reference

#####################################################################
#
# Scrape the design detail page.  It will have links to a color change page.
# From the color change page, there will be access to a link that will
# download a PDF file.
#
def designDetail(productID, url):
    r = requests.get(url)
    soup = BeautifulSoup(r.content, 'html.parser')
    anchor = soup.select('a#ColorChangeLink')
    if not anchor:
        print("No Color Change Link")
        return
    href = anchor[0].get('href')
    downloadPDF(productID, href)

#####################################################################
#
#
#
def downloadPDF(productID, href):
    chunk_size = 2048
    # productID is needed as a query parameter.
    payload = {}
    payload['productID'] = productID
    # Prepare the post data.  This will consist of a couple of hidden input
    # fields and a hard coded string generated by some javascript.
    postData = {}
    postData = {'__EVENTTARGET': 'ctl00$MainContent$productRepeater$ctl00$MakePdfProduct'}
    url = 'http://www.emblibrary.com/EL/' + href
    r = requests.get(url)
    soup = BeautifulSoup(r.content, 'html.parser')
    # The product name is used to form the folder and file name that
    # will store the downloaded color change PDF.
    productName = soup.select('table.content-item.info-table.padded.no-border > tr td:nth-of-type(2)')[0].text.strip()
    print(productID, productName, sep='-')
    # Select the hidden tags from the DOM. Add the hidden values to
    # the post data within a dictionary.
    hidden_tags = soup.select('input[type=hidden]')
    for tag in hidden_tags:
        postData[tag['name']] = tag['value']
    # Request the PDF.
    r = requests.post(url, params=payload, data=postData)
    dirPath = './AAATemp/' + productID + ' ' + productName + '/'
    os.makedirs(dirPath, exist_ok=True)
    filePath =  productID + ' ' + productName + '.pdf'
    # Open the folder and file to save the PDF.  Write it out chunk_size
    # at a time.
    with open(dirPath + filePath, 'wb') as fd:
        for chunk in r.iter_content(chunk_size):
            fd.write(chunk)

#####################################################################
# Control the main loop.
#
if __name__ == "__main__":
    signal.signal(signal.SIGINT, signal_handler)
    folderInitialize()
    url = keyBoardInput()
    if url is None:
        print("Problem entering date.")
    else:
        print(url)
        findLinks(url)
